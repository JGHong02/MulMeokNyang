{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d53c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Necessary libraries\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "480d1773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e12bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_rotation = torchvision.transforms.RandomApply([\n",
    "    torchvision.transforms.RandomRotation(20)\n",
    "], p=0.2)\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.RandomPerspective(distortion_scale=0.1, p=0.2),\n",
    "    transform_rotation,\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "transform_valid = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7019582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loade Data\n",
    "TRAIN_DATA_DIR = 'data/train'\n",
    "VALID_DATA_DIR = 'data/val'\n",
    "TEST_DATA_DIR = 'data/test'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(TRAIN_DATA_DIR,\n",
    "                                              transform=transform_train,\n",
    "                                              is_valid_file=lambda x: x.endswith('.jpg'))\n",
    "\n",
    "valid_data = torchvision.datasets.ImageFolder(VALID_DATA_DIR,\n",
    "                                              transform=transform_valid,\n",
    "                                              is_valid_file=lambda x: x.endswith('.jpg'))\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(TEST_DATA_DIR,\n",
    "                                             transform=transform_valid,\n",
    "                                             is_valid_file=lambda x: x.endswith('.jpg'))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=2, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valid_data, batch_size=BATCH_SIZE, num_workers=2)\n",
    "dataloaders_dict={}\n",
    "dataloaders_dict['train']= train_loader\n",
    "dataloaders_dict['val']= val_loader\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2499049",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHead(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_classes):\n",
    "        super(ModelHead, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.fc3 = torch.nn.Linear(hidden_dim // 2, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4360c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'checkpoints'\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "N_EPOCHS = 2\n",
    "\n",
    "def train(model, n_epochs, criterion, optimizer, train_data_loader, valid_data_loader,\n",
    "          device, model_save_path, logging_interval: int = 50):\n",
    "    best_valid_f1_score = 0.0\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # training step\n",
    "        model.train()\n",
    "\n",
    "        for batch_idx, (batch_data, batch_labels) in enumerate(train_data_loader):\n",
    "            inputs = batch_data.to(device)\n",
    "            y_true = batch_labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimizer step\n",
    "            y_pred = model(inputs)\n",
    "            loss = criterion(y_pred, y_true)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (batch_idx + 1) % logging_interval == 0:\n",
    "                print(f'Epoch: {epoch + 1}\\t| Batch: {batch_idx + 1}\\t| Loss: {loss}')\n",
    "\n",
    "        # validation step\n",
    "        model.eval()\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for valid_data, valid_labels in valid_data_loader:\n",
    "            valid_data = valid_data.to(device)\n",
    "            valid_labels = valid_labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                valid_preds = model(valid_data)\n",
    "            valid_pred_labels = torch.argmax(valid_preds, dim=1)\n",
    "            y_true.extend(valid_labels.detach().cpu().numpy())\n",
    "            y_pred.extend(valid_pred_labels.detach().cpu().numpy())\n",
    "        valid_f1_score = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "        if valid_f1_score > best_valid_f1_score:\n",
    "            best_valid_f1_score = valid_f1_score\n",
    "            torch.save(model.state_dict(),\n",
    "                       os.path.join(model_save_path, 'best_checkpoint.pth'))\n",
    "        print(f'Epoch {epoch + 1} F1-score: {valid_f1_score}\\t| Best F1-score: {best_valid_f1_score}')\n",
    "        torch.save(model.state_dict(),\n",
    "                   os.path.join(model_save_path, f'epoch_{epoch + 1}_checkpoint.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e31d950f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 3, 224, 224])\n",
      "Labels batch shape: torch.Size([32])\n",
      "Epoch: 1\t| Batch: 50\t| Loss: 0.9639856219291687\n",
      "Epoch 1 F1-score: 0.6120081333762154\t| Best F1-score: 0.6120081333762154\n",
      "Epoch: 2\t| Batch: 50\t| Loss: 0.482628732919693\n",
      "Epoch 2 F1-score: 0.6800966122140132\t| Best F1-score: 0.6800966122140132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.77        80\n",
      "           1       0.75      0.82      0.79        80\n",
      "           2       0.72      0.41      0.52        80\n",
      "           3       0.92      0.74      0.82        80\n",
      "           4       0.66      0.60      0.63        80\n",
      "           5       0.50      0.75      0.60        80\n",
      "           6       0.62      0.82      0.71        80\n",
      "           7       0.95      0.72      0.82        80\n",
      "           8       0.56      0.68      0.61        80\n",
      "           9       0.73      0.90      0.80        80\n",
      "          10       0.92      0.68      0.78        80\n",
      "          11       0.89      0.93      0.91        80\n",
      "\n",
      "    accuracy                           0.73       960\n",
      "   macro avg       0.76      0.73      0.73       960\n",
      "weighted avg       0.76      0.73      0.73       960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT).to(device)\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "model.fc = ModelHead(2048, 1024, 12)\n",
    "model.fc.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train(model, N_EPOCHS, criterion, optimizer,\n",
    "  train_data_loader, valid_data_loader,\n",
    "  device, MODEL_SAVE_PATH)\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_SAVE_PATH, 'best_checkpoint.pth')))\n",
    "model.eval()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for test_data, test_labels in test_data_loader:\n",
    "    test_data = test_data.to(device)\n",
    "    test_labels = test_labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        test_preds = model(test_data)\n",
    "    test_pred_labels = torch.argmax(test_preds, dim=1)\n",
    "    y_true.extend(test_labels.detach().cpu().numpy())\n",
    "    y_pred.extend(test_pred_labels.detach().cpu().numpy())\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f35d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
